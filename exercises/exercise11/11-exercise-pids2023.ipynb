{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5d2d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"11-exercise-pids2023.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0badb8",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-525c2fd5f3e93d2b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise sheet 11\n",
    "**Hello everyone!**\n",
    "\n",
    "**Points: 15**\n",
    "\n",
    "Topics of this exercise sheet are:\n",
    "* Correlation and Regression\n",
    "\n",
    "Please let us know if you have questions or problems! <br>\n",
    "Contact us during the exercise session, on [Piazza](https://piazza.com/class/leibdr4lk8n3w4), or [via email](https://sada.dmi.unibas.ch/en/teaching/pids23).\n",
    "\n",
    "Please submit this exercise sheet on **GRADESCOPE**.\n",
    "Naming conventions:\n",
    "* Name of notebook: \"11-exercise-pids2023.ipynb\"\n",
    "\n",
    "Your notebook will be automatically graded using gradescope. To get graded, you need to upload the file *11-exercise-pids2023.ipynb* to gradescope. If you are using JupyterHub, make sure you have saved the current notebook, then you can download this file by following: *File*->*Download* and save the file on you computer.\n",
    "\n",
    "The sheet is released before the exercise session on Tuesday. You have until the next exercise session on Tuesday to submit this sheet. Most of the questions of the exercise sheet can be handle during the session.\n",
    "\n",
    "**Handout date**: 16.05.2023 <br>\n",
    "**Submission date**: 23.05.2023 before 16:00 <br>\n",
    "\n",
    "\n",
    "### Please name the variables as suggested! Be careful with the type! Otherwise the grading system will fail you!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19612d8a",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-41524afeb7ebe206",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nose.tools import assert_is_instance, assert_equal, assert_almost_equal, assert_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a17814",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-53460d34058f3491",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this exercise, we do a simple regression task using the correlation coefficient as discussed in the last lecture.\n",
    "At first, let's create the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e19ac2c",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-de32fce7c84d1792",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def perturbed_line_data(N):\n",
    "    np.random.seed(0)\n",
    "    x = np.random.uniform(low=-2, high=+2, size = N)\n",
    "    n = np.random.randn(N) * 0.1\n",
    "    a = np.random.rand(1)\n",
    "    b = np.random.rand(1)\n",
    "    y = (b +  a * x) + n\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "N = 200 # The number of samples\n",
    "x,y = perturbed_line_data(N)\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "ax.scatter(x, y, alpha=0.5)\n",
    "ax.spines['bottom'].set_position('zero')\n",
    "ax.spines['left'].set_position('zero')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20d044b",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6fcab90fcffa4ae2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1a (6 points)\n",
    "Let $(x,y)$ denote the points given by the function *perturbed_line_data*.\n",
    "Now we would like to predict the corresponding $\\hat{y}$ for a given $x_0$. As discussed in the last lecture, we can make a linear estimator as follows:\n",
    "$$\n",
    "\\hat{y} = \\mu_y +  \\rho ( \\dfrac{x_0- \\mu_x}{\\sigma_x} ) \\sigma_y\n",
    "$$\n",
    "In this section, we want to implement this linear estimator for the given dataset. So at first, calculate the correlation coefficient $\\rho$ and store it in variable \"rho\"; use this to calculate $\\hat{y}$ for all datapoint x and store it in variable \"y_hat\".\n",
    "\n",
    "Name your variables \"mu_x\", \"mu_y\", \"rho\", \"sigma_x\", \"sigma_y\" and \"y_hat\".\n",
    "\n",
    "Hint: All you need is Numpy!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f8dc066",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0f3266550e4db393",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "N = 200\n",
    "x,y = perturbed_line_data(N)\n",
    "\n",
    "...\n",
    "\n",
    "print('Correlation coefficient: {:0.3f}'.format(rho))\n",
    "ax = plt.subplot(111)\n",
    "ax.scatter(x, y, alpha=0.5)\n",
    "ax.plot(x, y_hat, alpha=0.5 , color = 'r')\n",
    "ax.spines['bottom'].set_position('zero')\n",
    "ax.spines['left'].set_position('zero')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41db2d9b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"Question 1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03df25af",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d06a3efacbebeaa9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Why is this estimator called \"linear\"? Can you explain it from the formula and the plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b21ebd",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-81061ad69c0d28c5",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8985d677",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0682fdc8882d815c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1b (2 points)\n",
    "Since we will use this linear estimator in the next parts, it is more convenient to make it a function that takes the samples $x$ and $y$ and the query point(s) $x_0$ as input and returns the predictions $\\hat{y}$ and correlation coefficient $\\rho$.\n",
    "Make sure that the function can take a vector $x_0$ as input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7277ea9",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-183fea12257ba84f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "N0 = 100\n",
    "x0 = np.linspace(-2,2,N0)\n",
    "\n",
    "def linear_regressor(x,y,x0):\n",
    "    ...\n",
    "    return y_hat, rho  \n",
    "\n",
    "y_hat, rho = linear_regressor(x,y,x0)\n",
    "print('Correlation coefficient: {:0.3f}'.format(rho))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a85b2f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"Question 1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9e29f1",
   "metadata": {},
   "source": [
    "### 1c (5 points)\n",
    "SciPy provides a linear regression function, called linregress, that similarly to our function returns the correlation coefficient. Please use the linregress function to calculate the regression line's slope, intercept, and correlation coefficient and store them respectively in variables \"slope\", \"intercept\" and \"rho_scipy\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2200cfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "N = 200\n",
    "x,y = perturbed_line_data(N)\n",
    "\n",
    "...\n",
    "\n",
    "N0 = 100\n",
    "x0 = np.linspace(-2,2,N0)\n",
    "print('Correlation coefficient: {:0.3f}'.format(rho_scipy))\n",
    "ax = plt.subplot(111)\n",
    "ax.scatter(x, y, alpha=0.5)\n",
    "ax.plot(x0, slope * x0 + intercept, alpha=0.5 , color = 'r')\n",
    "ax.spines['bottom'].set_position('zero')\n",
    "ax.spines['left'].set_position('zero')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd9059d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"Question 1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f5853e",
   "metadata": {},
   "source": [
    "## Non-linear dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1879e6db",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8b422fb9981a08b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We want to assess the performance of our linear regression over a more complicated dataset. At first, let's create it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5914614e",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-768a91b3704f8765",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def perturbed_cos_data(N):\n",
    "    np.random.seed(0)\n",
    "    x = np.random.uniform(low = -10 , high = 10 , size = N)\n",
    "    n = np.random.rand(N) * 0.5\n",
    "    y = np.cos(0.5*x) + n\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "N = 500 # The number of samples\n",
    "x,y = perturbed_cos_data(N)\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "ax.scatter(x, y, alpha=0.5)\n",
    "ax.spines['bottom'].set_position('zero')\n",
    "ax.spines['left'].set_position('zero')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbec765",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3b593abf923267bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2a (2 points)\n",
    "Now let's calculate $\\hat{y}$ and correlation coefficient from the linear regressor function over this dataset.\n",
    "Compute the prediction $\\hat{y}$ over 200 points uniformly spaced between -10 and 10.\n",
    "\n",
    "Name the resulting variables \"y_hat_cos\" and \"rho_cos\". Name the 200 sampling points \"x0\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e7a330a1",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0fc29f611eb1bca7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "N = 500 # The number of samples\n",
    "x,y = perturbed_cos_data(N)\n",
    "\n",
    "...\n",
    "\n",
    "print('Correlation coefficient: {:0.3f}'.format(rho_cos))\n",
    "ax = plt.subplot(111)\n",
    "ax.scatter(x, y, alpha=0.5)\n",
    "ax.plot(x0, y_hat_cos, alpha=0.5 , color = 'r')\n",
    "ax.spines['bottom'].set_position('zero')\n",
    "ax.spines['left'].set_position('zero')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b782fc30",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"Question 2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ea2865",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a7b19b136d15557d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Is this a reasonable estimation? How can we design a better estimator?\n",
    "\n",
    "Can you compare $\\rho$ for these two datasets? Which one is greater, and what does it mean to you?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95d8c96",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-dfab7379a295c647",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ac190ac",
   "metadata": {},
   "source": [
    "## 3) (Bonus) Non-linear regression (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb7c0e5",
   "metadata": {},
   "source": [
    "We saw with the previous example the limit of the linear model to predict a dateset. When the dataset follow a more complicated trend, we can try to find a more complicated function that reproduce this trend. *Scipy* provide a function called *curve_fit* that can help you with that. \n",
    "\n",
    "Using this function, try your best to approximate the dataset given by *perturbed_cos_data*.\n",
    "Name the function to fit \"func\" and the output of the *curve_fit* function \"popt\" and \"pcov\" (as in the documentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e09e6440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "N = 500 # The number of samples\n",
    "x,y = perturbed_cos_data(N)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6b20e1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"Question 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94011b90",
   "metadata": {},
   "source": [
    "We now display the estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ef906ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "N0 = 200\n",
    "x0 = np.linspace(-10,10,N0)\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "ax.scatter(x, y, alpha=0.5,label='Data')\n",
    "ax.plot(x0, y_hat_cos, alpha=0.5 , color = 'r',label='Linear estimation')\n",
    "ax.spines['bottom'].set_position('zero')\n",
    "ax.spines['left'].set_position('zero')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.plot(x0, func(x0, *popt), 'g--',label='Non-linear estimation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9f9ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67dd53c7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc77a07",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b688b74df3a1bcefd807d24cf2939be60cf5445cf0aad86130d8d6bd0752a400"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
